{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic segmentation.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOLUIebD7l1xWbVz85uovW5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anasnafis77/Deteksi-Glaukoma/blob/main/Semantic_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxjFeNlnmxqZ"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "%matplotlib inline\n",
        "\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import cv2\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ldp-PGUmmLmB"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qvjBZNTmumf"
      },
      "source": [
        "df = pd.read_json('/content/gdrive/My Drive/Drive Tugas Akhir/Kode/dataframe.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl9ImglFobC2"
      },
      "source": [
        "img_drishti = cv2.imread(df['path'][0], 0)\n",
        "img_refuge = cv2.imread(df['path'][50], 0)\n",
        "input_shape_drishti = img_drishti.shape\n",
        "input_shape_refuge = img_refuge.shape\n",
        "print(input_shape_drishti)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR2bPNh9Q8IX"
      },
      "source": [
        "def rectfromcenter(center, s, h, w):\n",
        "  x, y = center\n",
        "  x0 = round(x - 0.5*s)\n",
        "  x1 = round(x + 0.5*s)\n",
        "  y0 = round(y - 0.5*s)\n",
        "  y1 = round(y + 0.5*s)\n",
        "\n",
        "  # penanganan kasus out of image\n",
        "  if (x0 < 0):\n",
        "    x1 = x1 + (-x0)\n",
        "    x0 = x0 + (-x0)\n",
        "  elif (x1 > w-1):\n",
        "    x0 = x0 - (x1-(w-1))\n",
        "    x1 = x1 - (x1-(w-1))\n",
        "\n",
        "  if (y0 < 0):\n",
        "    y1 = y1 + (-y0)\n",
        "    y0 = y0 + (-y0)\n",
        "  elif (y1 > h-1):\n",
        "    y0 = y0 - (y1-(h-1))\n",
        "    y1 = y1 - (y1-(h-1))\n",
        "\n",
        "  return y0, y1, x0, x1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xYPfU0IMynD"
      },
      "source": [
        "# Fungsi untuk mengekstrak ROI\n",
        "# input : list centroid, panjang sisi ROI (s), dan image \n",
        "# output : ROI image\n",
        "\n",
        "def ekstrakROI(centroid, s, img):\n",
        "\n",
        "  h, w = img.shape[:2]\n",
        " \n",
        "  y0, y1, x0, x1 = rectfromcenter(centroid, s, h, w)\n",
        "\n",
        "  #cropping ROI from source image\n",
        "  ROI = img[y0:y1+1, x0:x1+1]\n",
        "  koordinat = (y0, y1, x0, x1)\n",
        "\n",
        "  return ROI, koordinat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL-1JlKlY_nt"
      },
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPsUk_kRo-kT"
      },
      "source": [
        "X = []\n",
        "y_OD = []\n",
        "y_OC = []\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "for i in tqdm_notebook(range(0, len(df))):\n",
        "  center = df['disc_center'][i]\n",
        "  img = cv2.imread(df['path'][i], 1)[:,:,1]\n",
        "  img = clahe.apply(img)\n",
        "  gt_OD = cv2.imread(df['path_OD_png'][i], 0)\n",
        "  gt_OC = cv2.imread(df['path_OC_png'][i], 0)\n",
        "\n",
        "  img,_ = ekstrakROI(center, 550, img)\n",
        "  gt_OD,_ = ekstrakROI(center, 550, gt_OD)\n",
        "  gt_OC,_ = ekstrakROI(center, 550, gt_OC)\n",
        "  img = resize(img, (256, 256, 1), mode = 'constant', preserve_range = True)\n",
        "  gt_OD = resize(gt_OD, (256, 256, 1), mode = 'constant', preserve_range = True)\n",
        "  gt_OC = resize(gt_OC, (256, 256, 1), mode = 'constant', preserve_range = True)\n",
        "  X.append(img/255.0)\n",
        "  y_OD.append(gt_OD/255.0)\n",
        "  y_OC.append(gt_OC/255.0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTAZHziB5Eyh"
      },
      "source": [
        "X = np.array(X)\n",
        "y_OD = np.array(y_OD)\n",
        "y_OC = np.array(y_OC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQOpKmxfnNuM"
      },
      "source": [
        "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
        "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
        "    # first layer\n",
        "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
        "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    # second layer\n",
        "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
        "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    return x\n",
        "  \n",
        "def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n",
        "    # Contracting Path\n",
        "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    p1 = Dropout(dropout)(p1)\n",
        "    \n",
        "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    p2 = Dropout(dropout)(p2)\n",
        "    \n",
        "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "    p3 = Dropout(dropout)(p3)\n",
        "    \n",
        "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "    p4 = Dropout(dropout)(p4)\n",
        "    \n",
        "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    # Expansive Path\n",
        "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    u6 = Dropout(dropout)(u6)\n",
        "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    u7 = Dropout(dropout)(u7)\n",
        "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    u8 = Dropout(dropout)(u8)\n",
        "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
        "    u9 = concatenate([u9, c1])\n",
        "    u9 = Dropout(dropout)(u9)\n",
        "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
        "    \n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "    model = Model(inputs=[input_img], outputs=[outputs])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnbo3GH0qOgT"
      },
      "source": [
        "X_train_OD, X_test_OD, y_train_OD, y_test_OD = train_test_split(X, y_OD, \n",
        "                                                                test_size=0.2, \n",
        "                                                                random_state = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wc6YWO2vI21"
      },
      "source": [
        "input_img = Input((256,256, 1), name='img')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZiEHJHAvOJk"
      },
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(patience=10, verbose=1),\n",
        "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),\n",
        "    ModelCheckpoint('model-tgs-salt.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfWosLL9oOU5"
      },
      "source": [
        "model = get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True)\n",
        "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r3b0GvUBjn1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6fzH1Joqye3"
      },
      "source": [
        "results = model.fit(X_train_OD, y_train_OD, batch_size=32, epochs=50, callbacks=callbacks,\\\n",
        "                    validation_data=(X_test_OD, y_test_OD))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRdeOviy7V4e"
      },
      "source": [
        "plt.figure(figsize=(14, 7))\n",
        "plt.title(\"Learning curve\")\n",
        "plt.subplot(122),\n",
        "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
        "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"log_loss\")\n",
        "plt.legend()\n",
        "plt.subplot(121), \n",
        "plt.plot(results.history[\"accuracy\"], label=\"accuracy\")\n",
        "plt.plot(results.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "plt.plot( np.argmin(results.history[\"val_accuracy\"]), np.min(results.history[\"val_accuracy\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"log_loss\")\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K7uF0m3DM8H"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNhlz8CdtKwD"
      },
      "source": [
        "# load the best model\n",
        "model.load_weights('model-tgs-salt.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vnkg-7xAtKwE"
      },
      "source": [
        "# Evaluate on validation set (this must be equals to the best log_loss)\n",
        "model.evaluate(X_test_OD, y_test_OD, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TExDD6AtKwE"
      },
      "source": [
        "# Predict on train, val and test\n",
        "preds_train = model.predict(X_train_OD, verbose=1)\n",
        "preds_val = model.predict(X_test_OD, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb8_268wtKwE"
      },
      "source": [
        "# Threshold predictions\n",
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "preds_val_t = (preds_val > 0.5).astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfbllJBOtKwE"
      },
      "source": [
        "def plot_sample(X, y, preds, binary_preds, ix=None):\n",
        "    \"\"\"Function to plot the results\"\"\"\n",
        "    if ix is None:\n",
        "        ix = random.randint(0, len(X))\n",
        "\n",
        "    has_mask = y[ix].max() > 0\n",
        "\n",
        "    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
        "    ax[0].imshow(X[ix, ..., 0], cmap='gray')\n",
        "    if has_mask:\n",
        "        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
        "    ax[0].set_title('Seismic')\n",
        "\n",
        "    ax[1].imshow(y[ix].squeeze(), cmap='gray')\n",
        "    ax[1].set_title('Salt')\n",
        "\n",
        "    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n",
        "    if has_mask:\n",
        "        ax[2].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
        "    ax[2].set_title('Salt Predicted')\n",
        "    \n",
        "    ax[3].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=1)\n",
        "    if has_mask:\n",
        "        ax[3].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
        "    ax[3].set_title('Salt Predicted binary');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd79Qk2BDb2q"
      },
      "source": [
        "# Plot image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSbQLEzntKwF"
      },
      "source": [
        "# Check if training data looks all right\n",
        "plot_sample(X_train_OD, y_train_OD, preds_train, preds_train_t, ix=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmRgk9M6tKwF"
      },
      "source": [
        "plot_sample(X_train_OD, y_train_OD, preds_train, preds_train_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKGSDdbltKwF"
      },
      "source": [
        "plot_sample(X_train, y_train, preds_train, preds_train_t)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}